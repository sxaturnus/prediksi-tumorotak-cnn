# -*- coding: utf-8 -*-
"""Prediksi_TumorOtak_CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qmcuxpgE8UzBJTNSG1goDrCc1eTw9RPn
"""

!pip install Pillow numpy tensorflow opencv-python matplotlib

from PIL import Image
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout
import cv2
import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)
import matplotlib.pyplot as plt
import io
from google.colab import files

"""**1. Import Data**

Buat function untuk import data gambar manual dari device
"""

from zipfile import ZipFile

# Upload ZIP file berisi dataset (struktur: Tumor/, No_Tumor/)
uploaded = files.upload()

# Ekstrak zip-nya
for filename in uploaded.keys():
    with ZipFile(filename, 'r') as zip_ref:
        zip_ref.extractall('dataset')

def load_images_with_labels(base_dir):
    images = []
    labels = []
    label_map = {'no_tumor': 0, 'tumor': 1}

    for label_name in os.listdir(base_dir):
        folder_path = os.path.join(base_dir, label_name)
        if os.path.isdir(folder_path):
            for filename in os.listdir(folder_path):
                img_path = os.path.join(folder_path, filename)
                try:
                    img = Image.open(img_path)
                    img = img.resize((224, 224))
                    img = img.convert('RGB')
                    img = np.array(img) / 255.0
                    images.append(img)
                    labels.append(label_map[label_name.lower()])
                except Exception as e:
                    print(f"Error loading image {img_path}: {e}")

    return np.array(images), np.array(labels)

# Jalankan fungsi
X, y = load_images_with_labels("dataset")
print("Jumlah data:", len(X))
print("Dimensi gambar:", X[0].shape)
print("Label unik:", np.unique(y))

"""definisikan function load_images()"""

from PIL import Image
import os
import numpy as np

def load_images(directory):
    images = []
    for filename in os.listdir(directory):
        img_path = os.path.join(directory, filename)
        try:
            img = Image.open(img_path)
            img = img.resize((224, 224))
            img = img.convert('RGB')
            img = np.array(img) / 255.0  # Normalisasi
            images.append(img)
        except Exception as e:
            print(f"Gagal load {filename}: {e}")
    return images

"""unzip dataset ke direktori /content/data/"""

import zipfile

with zipfile.ZipFile('/content/brain_tumor_dataset.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/data')

"""visualisasi awal dataset, tampilkan 5 img"""

import os

# Lihat isi folder /content/data
print("Isi folder /content/data:")
print(os.listdir('/content/data'))

"""- set ukuran figsize 20x10
- looping 5x utk gambar Tumor Picture & No Tumor Picture
"""

tumor_images = load_images('/content/data/Tumor')
no_tumor_images = load_images('/content/data/No_Tumor')

fig, axes = plt.subplots(2, 5, figsize=(20, 10))

for i in range(5):
    axes[0, i].imshow(tumor_images[i])
    axes[0, i].set_title('Tumor Picture')
    axes[0, i].axis('off')

for i in range(5):
    axes[1, i].imshow(no_tumor_images[i])
    axes[1, i].set_title('No Tumor Picture')
    axes[1, i].axis('off')

plt.show()

"""cek tipe data hasil load img"""

type(tumor_images)

"""cek jumlah img per kategori"""

len(tumor_images)
len(no_tumor_images)

"""tampilkan seluruh isi list gambar tumor_images"""

tumor_images

"""**2. Labelling**"""

def assign_labels(tumor_images, no_tumor_images):
    tumor_labels = np.ones(len(tumor_images))
    no_tumor_labels = np.zeros(len(no_tumor_images))
    return tumor_labels, no_tumor_labels
tumor_labels, no_tumor_labels = assign_labels(tumor_images, no_tumor_images)

"""gambar tumor di labelkan dgn = 1"""

tumor_labels

"""gambar no tumor di labelkan dgn = 0"""

no_tumor_labels

"""cek tipe data dari tumor_labels"""

type(tumor_labels)

"""- gabungkan semua img jadi 1 list
- gabungkan semua label jadi 1 array NumPy
- convert list ke array agar bisa dipakai model TensorFlow
"""

data = tumor_images + no_tumor_images
labels = np.concatenate((tumor_labels, no_tumor_labels), axis=0)

# Konversi list gambar ke array numpy
data = np.array(data)

print("Data shape:", data.shape)
print("Labels shape:", labels.shape)

data

labels

"""cek dimensi(shape) dari data"""

data[0].shape

"""**3. Spliting Data**

lakukan inisialisasi data dgn ketentuan:
x = berisi gambar yang udah distandarkan (224x224x3)
y = berisi label 0 atau 1

konversi ini penting karena library TensorFlow hanya memproses data dalam bentuk numpy.array saja
"""

X = np.array(data)
y = np.array(labels)

"""lakukan spliting data dengan:
- 20% data testing
- 80% data training
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

"""**Konversi Data ke TensorFlow Dataset**
- variable train => create dataset TensorFlow dari variable x_train & y_train
- variable test => create dataset TensorFlow dari varibale x_test & y_test
"""

train = tf.data.Dataset.from_tensor_slices((X_train, y_train))
test = tf.data.Dataset.from_tensor_slices((X_test, y_test))

"""Tampilkan 5 gambar dari data training. Buat cek visual: apakah data sdh benar dan label cocok?"""

for image, label in train.take(5):
    plt.figure()
    plt.imshow(image.numpy())
    plt.title('Label: {}'.format(label.numpy()))
    plt.axis('off')
    plt.show()

"""split sebagian kecil data training (~10%) buat validasi model saat training"""

validation_size = int(0.1 * 202)  # Misal jumlah data train = 202
train = train.skip(validation_size)
val = train.take(validation_size)

"""Training pakai batch biar lebih cepat dan hemat memori. Default batch size 32 (standar)"""

BATCH_SIZE = 32
train = train.batch(BATCH_SIZE)
test = test.batch(BATCH_SIZE)
val = val.batch(BATCH_SIZE)

"""**4. Training Data**

**Inisialisasikan sequential dengan features extraction:**
- Convutional 2D dengan input_shape = (224,224,3)
- Gunakan MaxPooling2D utk performa yang lbh baik dibandingkan AvgPooling
- Tambahkan Flatten
- Fungsi aktivasi gunakan ReLU & Sigmoid (cocok utk data binary)
- Dense dimulai dari 0 ke 1
"""

model = Sequential()

model.add(Conv2D(32, (3,3), activation = 'relu', input_shape = (224,224,3), padding='valid'))
model.add(MaxPooling2D((2,2)))
model.add(Flatten())
model.add(Dense(256, activation = 'relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation = 'sigmoid'))

"""tampilkan arsitektur dari proses features extraction"""

model.summary()

"""**Compile & Training**"""

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

"""Latih model selama 20 epochs, sambil monitor akurasi & loss di validation set."""

history = model.fit(train, validation_data = val, epochs = 20, verbose = 1)

"""cek seberapa bagus performa model pada data baru yang belum pernah dilihat"""

evaluation = model.evaluate(test)

"""**Plot Akurasi & Loss** => utk monitor progres training"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.legend(['Accuracy', 'Val Accuracy'], loc = 'upper right')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.show()

"""visualisasi nilai loss"""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['loss', 'Val Loss'], loc = 'upper right')
plt.title('Loss')
plt.xlabel('epochs')
plt.ylabel('Loss')
plt.show()

from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Prediksi data test
y_pred_prob = model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype("int32").flatten()

# Buat confusion matrix
cm = confusion_matrix(y_test, y_pred)
cr = classification_report(y_test, y_pred, target_names=["Tumor", "No_Tumor"])  # Ganti label sesuai dataset

print("📋 Classification Report:\n", cr)

# Plot confusion matrix
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["yes", "no"], yticklabels=["yes", "no"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

"""simpan hasil training data ke local device"""

# 1. Simpan model ke .h5
model.save("tumor_model.h5")
print("✅ Model berhasil disimpan sebagai 'tumor_model.h5'")

# 2. Download file langsung dari Colab
from google.colab import files
files.download("tumor_model.h5")

"""**5. Testing**

- Load & Preprocess Gambar
- Buat function utk prediksi gambar
"""

def load_uploaded_image(image_bytes):
    img = Image.open(io.BytesIO(image_bytes))
    img = img.resize((224, 224))
    img_array = np.array(img)
    img_array = img_array / 255.0
    return img_array

def predict_image(image_bytes):
    img_array = load_uploaded_image(image_bytes)
    img_array = np.expand_dims(img_array, axis=0)
    prediction = model.predict(img_array)
    if prediction[0][0] > 0.5:
        return "Tumor detected"
    else:
        return "No tumor detected"

"""upload img -> tampilkan gambar -> output hasil prediksi"""

uploaded = files.upload()
file_name = list(uploaded.keys())[0]
image_bytes = uploaded[file_name]

img = Image.open(io.BytesIO(image_bytes))
plt.imshow(img)
plt.axis('off')
plt.title("Uploaded Image")
plt.show()

result = predict_image(image_bytes)
print("🔍 Hasil Prediksi:", result)